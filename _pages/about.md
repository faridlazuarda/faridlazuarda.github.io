---
layout: about
title: about
permalink: /
subtitle: Hi, I'm Farid! 

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular

news: true # includes a list of news items
selected_papers: false # includes a list of papers marked as "selected={true}"
social: false # includes social icons at the bottom of the page
---
I’m a PhD student at the [University of Edinburgh](https://www.ed.ac.uk/), where I’m fortunate to be advised by [Edoardo Ponti](https://ducdauge.github.io/) and [Alexandra Birch](https://people.inf.ed.ac.uk/Alexandra_Birch-Mayne.html). I’m a member of the [Institute for Language, Cognition and Computation (ILCC)](https://informatics.ed.ac.uk/ilcc) and the [Edinburgh NLP Group](https://edinburghnlp.inf.ed.ac.uk/).

My research asks a big question: <strong>How can we design language models that are both compute-efficient and multilingual, so they can <em>reason better</em> under tight budgets and across languages?</strong> To answer this, I focus on improving the <strong>efficiency of neural models</strong>, with a particular interest in methods that could enable tokenization-free and more compute-optimal architectures. Currently, I work on <strong>adaptive memory compression</strong> for faster inference and <strong>multilinguality</strong>, aiming to build models that perform well across diverse languages.

Before Edinburgh, I was a Research Assistant at [MBZUAI](https://mbzuai.ac.ae/) in Abu Dhabi and a visiting researcher at the [UKP Lab, TU Darmstadt](https://www.informatik.tu-darmstadt.de/ukp), where I worked on multilingual, multicultural, and parameter-efficient NLP—topics I still enjoy discussing!

I know how much research success can depend on access and opportunity. If you’re from an underrepresented group and think a conversation might help, feel free to reach out by [email](mailto:farid.adilazuarda@ed.ac.uk).
